<?xml version="1.0" encoding="UTF-8"?>

<article xmlns="http://docbook.org/ns/docbook" xmlns:xl="http://www.w3.org/1999/xlink" version="5.0"
  xml:lang="en">

  <info>

    <title>Linked Data Templates</title>

    <subtitle>Ontology-driven approach to read-write Linked Data</subtitle>

    <authorgroup>
      <author>
        <personname>
          <firstname>Martynas</firstname>
          <surname>Jusevičius</surname>
        </personname>
        <email>martynas@atomgraph.com</email>
        <affiliation>
          <orgname>AtomGraph</orgname>
        </affiliation>
      </author>
    </authorgroup>

    <keywordset>
      <keyword>HTTP</keyword>
      <keyword>REST</keyword>
      <keyword>RDF</keyword>
      <keyword>Linked Data</keyword>
      <keyword>SPARQL</keyword>
      <keyword>XSLT</keyword>
      <keyword>SPIN</keyword>
      <keyword>declarative</keyword>
      <keyword>data-driven</keyword>
    </keywordset>

    <abstract>
      <para>In this paper we summarize the architecture of Linked Data Templates, a uniform protocol
        for read-write Linked Data.</para>
      <para>We start by overviewing existing approaches as well as protocol constraints, and propose
        a declarative approach based on URI-representation mapping, defined as templates. We then
        introduce an abstract model for RDF CRUD interactions based on template matching, outline
        the processing model, and provide an example.</para>
      <para>We conclude that LDT provides a new way to build applications and can be used to
        implement the ontology-driven Semantic Web vision.</para>
    </abstract>

  </info>

  <section>

    <title>Introduction</title>

    <para>Linked Data is a vast source of information available in RDF data model. In this paper we
      describe Linked Data Templates: a generic method for software agents to publish and consume
      read-write Linked Data. By doing so, we facilitate a distributed web as well as redefine the
      software development process in a declarative manner.</para>
    <para>Web applications duplicate a lot of domain-specific code across imperative programming
      language implementations. We abstract application logic away from source code and capture it
      in a machine-processable representation that enables reuse, composition, and reasoning. Our
      goal is to permit software to operate on itself through metaprogramming to generate
      higher-level applications — a feature not available in imperative languages. Having a uniform
      homoiconic representation, we reduce application state changes to uniform Create, Read,
      Update, Delete (CRUD) interactions on Linked Data representations <xref linkend="crud"
      />.</para>
    <para>Linked Data representations describe application resource properties. A consuming process
      can query and change resource state by issuing requests to resource URIs. On the producing
      end, representations are generated from an RDF dataset, either stored natively in a
      triplestore or mapped from another data model. The exact logic of how representations are
      generated and stored is application-specific.</para>
    <para>By establishing a mapping between URI address space and the RDF representation space, we
      can model application structure in terms of RDF classes that map URIs to RDF queries and
      updates. We choose RDF-based ontologies as the LDT representation, as it is the standard way
      to define classes and satisfies both the machine-processability and the homoiconicity
      requirements. Ontology as a component for application structure is what distinguishes LDT from
      other Linked Data specifications such as Linked Data Platform.</para>
    <para>In the following sections, we explain the motivation behind LDT and describe the LDT
      architecture in more detail. First we establish that applications can be driven by ontologies
      that can be composed. We then introduce templates, special ontology classes that map URI
      identifiers to request-specific SPARQL strings. We proceed to describe how a process matching
      templates against request URI is used by RDF CRUD interactions that generate Linked Data
      descriptions from an RDF dataset and change the dataset state. Lastly, we map the interactions
      to the HTTP protocol and show how the client can use HTTP to interact with LDT
      applications.</para>

  </section>

  <section>

    <title>Distributed web as read-write Linked Data</title>

    <section>

      <title>A protocol for the web of data</title>

      <para>Smart software agents should navigate the web of data and perform tasks for their users
        — that has been an early optimistic vision of the Semantic Web <xref
          linkend="the-semantic-web"/>. Ontologies and ontology-driven agents were central to this
        vision, to provide the means to capture domain logic in a way that sustains reason. It was
        largely forgotten when the high expectations were not met, and the community focus shifted
        to the more pragmatic Linked Data.</para>

      <para>In order to enable smart agents, we need to provide a uniform protocol for them to
        communicate. Such a protocol, understood by all agents in the ecosystem, decouples software
        from domain- or application-specific logic and enables generic implementations. The web has
        thrived because HTTP is such protocol for HTML documents, and web browsers are generic
        agents.</para>

      <para>REST readily provides uniform interface for a protocol, which has been successfully
        implemented in HTTP. The interface is defined using 4 constraints <xref linkend="rest"
        />:</para>

      <itemizedlist mark="bullet">
        <listitem>
          <para>identification of resources</para>
        </listitem>
        <listitem>
          <para>manipulation of resources through representations</para>
        </listitem>
        <listitem>
          <para>self-descriptive messages</para>
        </listitem>
        <listitem>
          <para>hypermedia as the engine of application state</para>
        </listitem>
      </itemizedlist>

      <para>Since the Linked Data resource space is a subset of REST resource space, we can look at
        how these constraints apply to standard Linked Data technologies:</para>

      <itemizedlist mark="bullet">
        <listitem>
          <para>URIs identify resources</para>
        </listitem>
        <listitem>
          <para>RDF is used as resource representation. Resource state can be changed using RDF CRUD
            interactions.</para>
        </listitem>
        <listitem>
          <para>RDF formats are used for self-describing Linked Data requests and responses</para>
        </listitem>
      </itemizedlist>

    </section>

    <section>

      <title>Ontology-driven Linked Data</title>

      <para>The main point of interest for this paper is RDF CRUD interactions, the central yet
        underspecified component of read-write Linked Data. The only standard in this area is W3C
        Linked Data Platform 1.0 specification, which defines a set of rules for HTTP interactions
        on web resources, some based on RDF, to provide an architecture for read-write Linked Data
        on the web <xref linkend="ldp"/>. It has several shortcomings:</para>

      <itemizedlist mark="bullet">
        <listitem>
          <para>It is coupled with HTTP and provides no abstract model for RDF CRUD</para>
        </listitem>
        <listitem>
          <para>In order to accommodate legacy systems, it does not mandate the use of SPARQL.
            SPARQL is the standard RDF query language and does provide an abstract model <xref
              linkend="sparql"/>.</para>
        </listitem>
        <listitem>
          <para>It does not offer a standard way for agents to customize how CRUD interactions
            change resource state</para>
        </listitem>
      </itemizedlist>

      <para>The Linked Data API specification defines a vocabulary and processing model for a
        configurable, yet read-only API layer intended to support the creation of simple RESTful
        APIs over RDF triple stores <xref linkend="lda"/>. Hydra Core Vocabulary is a lightweight
        vocabulary to create hypermedia-driven Web APIs and has similar goals to combine REST with
        Linked Data principles, but does not employ SPARQL and focuses on JSON-LD <xref
          linkend="hydra"/>.</para>

      <para>As we can see, currently popular Linked Data access methods are either read-only or do
        not use SPARQL. They use lightweight RDF vocabularies, but not formal ontologies that enable
        reasoning, as does the original ontology-driven Semantic Web vision. Although there has been
        a fair share of research and development in the area of ontology-driven applications <xref
          linkend="agent-web"/><xref linkend="ontology-driven"/>, it focuses mostly on domain and
        user interface modeling, and not representation manipulation modeling.</para>

    </section>

    <section>

      <title>LDT design</title>

      <para>We propose Linked Data Templates, an ontology-driven approach to read-write Linked Data.
        It builds on the following constraints:</para>

      <itemizedlist mark="bullet">
        <listitem>
          <para>there is a mapping between URI address space and the RDF representation space. It is
            used to determine resource’s representation from its URI identifier.</para>
        </listitem>
        <listitem>
          <para>applications are read-write and backed by SPARQL 1.1 compatible services to decouple
            them from database implementations</para>
        </listitem>
        <listitem>
          <para>application structure is defined in an ontology to enable reasoning and
            composition</para>
        </listitem>
        <listitem>
          <para>application state is driven by hypermedia (HATEOAS) to satisfy REST
            constraints</para>
        </listitem>
      </itemizedlist>

      <figure xml:id="ldt-components">
        <title>Main components of LDT architecture</title>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/components.svg" width="100%"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>XSLT is a homoiconic high-level language for the XML data model <xref linkend="xslt"/>.
        We wanted to follow this approach with a Linked Data specification, and as a result, XSLT
        heavily influenced the template-based design of LDT. We draw multiple parallels between XSLT
        stylesheets and LDT ontologies, XML source documents and RDF datasets, XPath patterns and
        URI templates etc.</para>

      <para>AtomGraph Processor<footnote>
          <para><link xl:href="https://github.com/AtomGraph/Processor">AtomGraph
            Processor</link></para>
        </footnote> is an open-source implementation of LDT. The commercial AtomGraph Platform<footnote>
          <para><link xl:href="http://atomgraph.com">AtomGraph Platform</link></para>
        </footnote> provides a multi-tenant environment and has been successfully used to build rich
        LDT applications for product information management and library data.</para>

    </section>

  </section>

  <section>

    <title>Application ontologies</title>

    <para><termdef>An LDT <firstterm>application</firstterm> represents a data space identified by
        its base URI, in which application resource URIs are relative to the base URI.</termdef> The
      only external interface an application provides is RESTful Linked Data: application produces
      RDF representations when resource URIs are dereferenced, and consumes RDF representations when
      requested to change resource state.</para>

    <para>Application structure, the relationships between its resources, is communicated through
      representations. Representations are generated from, and stored in, an RDF dataset. Two
      different applications should be able to use the same dataset yet expose different structures
      because they produce representations and change state differently. It follows that application
      structure can be defined as instructions for representation processing.</para>

    <para>An ontology is an efficient way to define such structure declaratively. We use OWL to
      define LDT application ontologies with RDF query and state change instructions specific to
      that application. We use SPARQL to encode these instructions, because it is the standard RDF
      query and update language and can be conveniently embedded in ontologies using SPIN RDF
      syntax. Using SPARQL service as the interface for the dataset, applications are independent
      from its implementation details.</para>

    <para>An LDT application ontology may comprise several ontologies, contained in different RDF
      graphs. For a given application, one of these serves as the <firstterm>principal
        ontology</firstterm>. Ontologies are composed through the standard <code>owl:imports</code>
      mechanism, with the additional concept of import precedence, which makes ontologies override
      each other depending on the import order. </para>

    <para>LDT does not make any assumptions about the application structure. There is however a
      useful one: a resource hierarchy consisting of a container/item tree. It is similar to the
      container/resource design in LDP, but based on the SIOC ontology instead <xref linkend="sioc"
      />. The vast majority of Web applications can be modeled using this structure.</para>
  </section>

  <section>

    <title>Templates</title>

    <para><termdef>A <firstterm>template</firstterm> is a declarative instruction contained in an
        ontology, defined using LDT vocabulary<footnote>
          <para>LDT vocabulary is planned to have <link xl:href="http://www.w3.org/ns/ldt#"/>
            namespace in the final specification</para>
        </footnote>, and driving RDF CRUD processing.</termdef> It is a special ontology class that
      maps a certain part of the application URI space to a certain SPARQL string. A template can be
      viewed as a function with URI as the domain and SPARQL as the range, which are the two
      mandatory parts of the template, detailed below.</para>

    <para>A template domain is defined using <code>ldt:path</code> property and a regex-based JAX-RS
      URI template syntax <xref linkend="jax-rs"/>. It is a generic way to define a class of
      resources based on their URI syntax: if an URI matches the template, its resource is a member
      of the class. Starting with a catch-all template that matches all resources in an application,
      we can specialize the URI pattern (e.g. by adding fixed paths) to narrow down the class of
      matching resources.</para>

    <para>A template range is defined using <code>ldt:query</code> property and SPIN RDF syntax,
      while updates use <code>ldt:update</code> property <xref linkend="spin"/>. URI that matches
      URI template is passed to SPARQL using a special variable binding <code>?this</code> (path
      variables from the URI template match, if any, are not used since URIs are opaque). Starting
      with the default query <code>DESCRIBE ?this</code>, we can specialize it with a graph pattern,
      for example to include descriptions of resources connected to ?this resource. The query forms
      are limited to <code>DESCRIBE</code> and <code>CONSTRUCT</code>, as the required result is RDF
      graph.</para>

    <para>An important feature of LDT templates is <firstterm>annotation inheritance</firstterm>,
      which enables code reuse but requires reasoning. It mimics object-oriented multiple
      inheritance: a class inherits annotation properties from its superclasses via the
        <code>rdfs:subClassOf</code> relation, unless it defines one or own properties of its own
      which override the inherited ones. SPIN takes a similar object-oriented world-view and uses
      subclass-based inheritance.</para>

  </section>

  <section>

    <title>Processing model</title>

    <para>We have established that application state is queried and changed using Linked Data
      requests that trigger RDF CRUD in the form of SPARQL. We can constrain the requests to 4 types
      of CRUD <firstterm>interactions</firstterm> that map to either SPARQL query or update. An
      interaction is triggered by a Linked Data request and results in query or change of
      application state by means of SPARQL execution <xref linkend="awww"/>.</para>

    <table>
      <title>LDT interaction types</title>
      <tgroup cols="3">
        <colspec colname="c1"/>
        <colspec colname="c2"/>
        <colspec colname="c3"/>
        <thead>
          <row>
            <entry>Interaction type</entry>
            <entry>SPARQL form</entry>
            <entry>Generated from</entry>
          </row>
        </thead>
        <tbody>
          <row>
            <entry>Create</entry>
            <entry><code>INSERT DATA</code></entry>
            <entry>request RDF entity</entry>
          </row>
          <row>
            <entry>Read</entry>
            <entry><code>DESCRIBE</code>/<code>CONSTRUCT</code></entry>
            <entry><code>ldt:query</code></entry>
          </row>
          <row>
            <entry>Update</entry>
            <entry><code>DELETE; INSERT DATA</code></entry>
            <entry><code>ldt:update;</code> request RDF entity</entry>
          </row>
          <row>
            <entry>Delete</entry>
            <entry><code>DELETE</code></entry>
            <entry><code>ldt:update</code></entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para><code>DESCRIBE</code> and <code>CONSTRUCT</code> forms are generated from
        <code>ldt:query</code> SPARQL templates; <code>DELETE</code> is generated from
        <code>ldt:update</code> SPARQL template. <code>INSERT DATA</code> is generated from the RDF
      in the request entity, either as triples or as quads. Update interaction combines two updates
      into one SPARQL request.</para>

    <para><termdef>We refer to the software that uses application templates to support the
        interaction as an LDT <firstterm>processor</firstterm>.</termdef> A processor consists of
      several sub-processes that are triggered by a Linked Data request and executed in the
      following order:</para>

    <orderedlist>
      <listitem>
        <para>A validation process validates incoming RDF representations against SPIN constraints
          in the ontology. Invalid data is rejected as bad request. Only applies to Create and
          Update.</para>
      </listitem>
      <listitem>
        <para>A skolemization process matches request RDF types against ontology classes and
          relabels blank nodes as URIs. Only applies to Create.</para>
      </listitem>
      <listitem>
        <para>A matching process matches the base-relative request URI against all URI templates in
          the application ontology, taking import precedence and JAX-RS priority algorithm into
          account. If there is no match, the resource is considered not found and the process
          aborts.</para>
      </listitem>
      <listitem>
        <para>A SPARQL generation process takes the SPARQL string from the matching template and
          applies <code>?this</code> variable binding with request URI value to produce a query or
          an update, depending on the interaction type. <code>BASE</code> is set to application base
          URI.</para>
      </listitem>
      <listitem>
        <para>A SPARQL execution process executes the query/update on the application’s SPARQL
          service. If there is a query result, it becomes the response entity.</para>
      </listitem>
      <listitem>
        <para>A response generation process serializes the response entity, if any. It uses content
          negotiation to select the most appropriate RDF format, sets response status code, adds
          ontology URI, matched template URI and inheritance rules as header metadata.</para>
      </listitem>
    </orderedlist>

    <para>For the container/item application structure it is convenient to extend this basic model
      with pagination, which allows page-based access to children of a container. It requires
        <code>SELECT</code> subqueries and extensions to query generation and response generation
      processes.</para>

    <para>Having access to application ontologies, LDT clients can infer additional metadata that
      helps them formulate successful requests. For example, SPIN constructors can be used to
      compose new resource representations from class instances, while SPIN constraints can be used
      to identify required resource properties. Applications with embedded clients become nodes of a
      distributed web, in which data flows freely between peers in either direction.</para>

    <section>

      <title>HTTP bindings</title>

      <para>The mapping to HTTP is straightforward — each interaction has a corresponding HTTP
        method:</para>

      <table>
        <title>LDT interaction mapping to HTTP</title>
        <tgroup cols="4">
          <colspec colname="c1"/>
          <colspec colname="c2"/>
          <colspec colname="c3"/>
          <colspec colname="c4"/>
          <thead>
            <row>
              <entry>Interaction type</entry>
              <entry>Request method</entry>
              <entry>Success statuses</entry>
              <entry>Failure statuses</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry morerows="1">Create</entry>
              <entry morerows="1"><code>POST</code></entry>
              <entry morerows="1"><code>201 Created</code></entry>
              <entry><code>400 Bad Request</code></entry>
            </row>
            <row>
              <entry><code>404 Not Found</code></entry>
            </row>
            <row>
              <entry>Read</entry>
              <entry><code>GET</code></entry>
              <entry><code>200 OK</code></entry>
              <entry><code>404 Not Found</code></entry>
            </row>
            <row>
              <entry morerows="1">Update</entry>
              <entry morerows="1"><code>PUT</code></entry>
              <entry><code>200 OK</code></entry>
              <entry><code>400 Bad Request</code></entry>
            </row>
            <row>
              <entry><code>201 Created</code></entry>
              <entry><code>404 Not Found</code></entry>
            </row>
            <row>
              <entry>Delete</entry>
              <entry><code>DELETE</code></entry>
              <entry><code>204 No Content</code></entry>
              <entry><code>404 Not Found</code></entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>It should be possible to use the <code>PATCH</code> method for partial modifications
        instead of replacing full representation with <code>PUT</code>, but that is currently
        unspecified.</para>

      <section>

        <title>Example</title>

        <para>In the following example, an HTTP client performs an Update-Read request flow on
          linkeddatahub.com application, which supports LDT. Only relevant HTTP headers are
          included.</para>

        <para>First, the client creates a resource representing Tim Berners-Lee by submitting its
          representation:</para>

        <programlisting language="http"><![CDATA[PUT /people/Berners-Lee HTTP/1.1
Host: linkeddatahub.com
Accept: text/turtle
Content-Type: text/turtle

@base         <http://linkeddatahub.com/people/Berners-Lee> .
@prefix ldt:  <http://www.w3.org/ns/ldt#> .
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix owl:  <http://www.w3.org/2002/07/owl#> .

<> a ldt:Document ;
  foaf:primaryTopic <#this> .

<#this> a foaf:Person ;
  foaf:primaryTopic <> ;
  owl:sameAs <https://www.w3.org/People/Berners-Lee/card#i> .
]]></programlisting>

        <para>Let's assume the match for <code>/people/Berners-Lee</code> request URI is the
            <code>:PersonDocument</code> template in the application ontology:</para>

        <programlisting language="turtle"><![CDATA[@base         <http://linkeddatahub.com/ontology> .
@prefix :     <#> .
@prefix ldt:  <http://www.w3.org/ns/ldt#> .
@prefix owl:  <http://www.w3.org/2002/07/owl#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix sp:   <http://spinrdf.org/sp#> .

: a ldt:Ontology ;
  owl:imports ldt: .

:PersonDocument a ldt:Template ;
  ldt:path "/people/{familyName}" ;
  ldt:update :DeleteWithPrimaryTopic ;
  rdfs:isDefinedBy : .

:DeleteWithPrimaryTopic a sp:DeleteWhere, ldt:Update ;
  sp:text """PREFIX  foaf: <http://xmlns.com/foaf/0.1/>
DELETE {
  ?this ?p ?o .
  ?primaryTopic ?primaryTopicP ?primaryTopicO .
}
WHERE
  { ?this ?p ?o
    OPTIONAL
      { ?this foaf:primaryTopic ?primaryTopic .
        ?primaryTopic ?primaryTopicP ?primaryTopicO
      }
  }""" .
]]></programlisting>

        <para>The variable binding <code>(?this,
            &lt;http://linkeddatahub.com/people/Berners-Lee&gt;)</code> is applied on the
            <code>DELETE</code> associated with the template. It is combined with <code>INSERT
            DATA</code> generated from the request RDF entity into a single update request.
          Application base URI is set on the final SPARQL string which is then executed on the
          SPARQL service behind the application:</para>

        <programlisting language="sparql"><![CDATA[BASE          <http://linkeddatahub.com/>
PREFIX  foaf: <http://xmlns.com/foaf/0.1/>
PREFIX  owl:  <http://www.w3.org/2002/07/owl#>
PREFIX  ldt:  <http://www.w3.org/ns/ldt#>

DELETE {
  <people/Berners-Lee> ?p ?o .
  ?primaryTopic ?primaryTopicP ?primaryTopicO .
}
WHERE
  { <people/Berners-Lee> ?p ?o
    OPTIONAL
      { <people/Berners-Lee> foaf:primaryTopic ?primaryTopic .
        ?primaryTopic ?primaryTopicP ?primaryTopicO
      }
  } ;

INSERT DATA {
  <people/Berners-Lee> a ldt:Document .
  <people/Berners-Lee> foaf:primaryTopic <people/Berners-Lee#this> .
  <people/Berners-Lee#this> a foaf:Person .
  <people/Berners-Lee#this> foaf:primaryTopic <people/Berners-Lee> .
  <people/Berners-Lee#this> owl:sameAs
<https://www.w3.org/People/Berners-Lee/card#i> .
}
]]></programlisting>

        <para>We assume the representation did not exist beforehand, so it is created instead of
          being updated (an optimized implementation might have skipped the <code>DELETE</code> part
          in this case). The application responds with:</para>

        <programlisting language="http"><![CDATA[HTTP/1.1 201 Created
Location: http://linkeddatahub.com/people/Berners-Lee
]]></programlisting>

        <para>The client can choose to follow the link to the newly created resource URI, and
          retrieve the same representation that was included with the initial <code>PUT</code>
          request (we omit that response):</para>

        <programlisting language="http"><![CDATA[GET /people/Berners-Lee HTTP/1.1
Host: linkeddatahub.com
Accept: text/turtle
]]></programlisting>

      </section>

    </section>

  </section>

  <section>

    <title>Future work</title>

    <para>The use of OWL and SPARQL is probably the biggest advantage and limitation of LDT at the
      same time. RDF ontology and query tools as well as developers are scarce for mainstream
      programming languages with the possible exception of Java, making implementations expensive
      and adoption slow. Query performance is a potential issue, albeit constantly improving and
      alleviated using proxy caching. On the other hand, OWL and SPARQL provide future-proof
      abstract models on which LDT builds.</para>

    <para>We are working around slow adoption of Linked Data by providing a hosted LDT application platform<footnote>
        <para><link xl:href="http://atomgraph.com">AtomGraph</link></para>
      </footnote>. It uses metaprogramming to implement complex data management features such as
      application and resource creation, autocompletion, access control, provenance tracking,
      faceted search — all done through a user interface, exposing as little technical RDF details
      as possible.</para>

    <para>We envision an ecosystem in which applications by different developers interact with each
      other: ask for permissions to access or create data, send notifications to users, automate
      interactions etc.</para>

  </section>

  <section>

    <title>Conclusions</title>

    <para>In this paper we have described how read-write Linked Data applications can be modeled
      using standard RDF/OWL and SPARQL concepts. Linked Data Templates enable a new way to build
      declarative software components that can run on different processors and platforms, be
      imported, merged, forked, managed collaboratively, transformed, queried etc. Experience with
      AtomGraph software has shown that such design is also very scalable, as the implementation is
      stateless and functional. We expect that substantial long-term savings in software engineering
      and development processes can be achieved using this approach.</para>

    <para>We have shown that SPARQL is the crucial link that reconciles ontology-driven Semantic Web
      and read-write Linked Data. Using SPARQL, Linked Data Templates define a protocol for
      distributed web of data as uniform RDF CRUD interactions. LDT already provide features from
      the original Semantic Web vision, such as ontology exchange between agents, and we are
      confident it has the potential to implement it in full.</para>

  </section>

  <bibliography>

    <biblioentry xml:id="crud" xreflabel="[1]">
      <abbrev>1</abbrev>
      <title>Create, read, update and delete</title>
      <publishername>Wikipedia, The Free Encyclopedia</publishername>
      <biblioid class="uri">https://en.wikipedia.org/wiki/Create,_read,_update_and_delete</biblioid>
    </biblioentry>

    <biblioentry xml:id="the-semantic-web" xreflabel="[2]">
      <abbrev>2</abbrev>
      <title>The Semantic Web</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Tim</firstname>
            <surname>Berners-Lee</surname>
          </personname>
        </author>
        <author>
          <personname>
            <firstname>James</firstname>
            <surname>Hendler</surname>
          </personname>
        </author>
        <author>
          <personname>
            <firstname>Ora</firstname>
            <surname>Lassila</surname>
          </personname>
        </author>
      </authorgroup>
      <publishername>Scientific American</publishername>
      <pubdate>1 May 2001</pubdate>
      <biblioid class="uri">http://www.scientificamerican.com/article/the-semantic-web/</biblioid>
    </biblioentry>

    <biblioentry xml:id="rest" xreflabel="[3]">
      <abbrev>3</abbrev>
      <title>Representational State Transfer (REST)</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Roy</firstname>
            <othername>Thomas</othername>
            <surname>Fielding</surname>
          </personname>
        </author>
      </authorgroup>
      <pubdate>2000</pubdate>
      <biblioid class="uri"
        >https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm#sec_5_1_5</biblioid>
    </biblioentry>

    <biblioentry xml:id="ldp" xreflabel="[4]">
      <abbrev>4</abbrev>
      <title>Linked Data Platform 1.0</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Steve</firstname>
            <surname>Speicher</surname>
          </personname>
        </author>
        <author>
          <personname>
            <firstname>John</firstname>
            <surname>Arwe</surname>
          </personname>
        </author>
        <author>
          <personname>
            <firstname>Ashok</firstname>
            <surname>Malhotra</surname>
          </personname>
        </author>
      </authorgroup>
      <publishername>World Wide Web Consortium (W3C)</publishername>
      <pubdate>26 February 2015</pubdate>
      <biblioid class="uri">https://www.w3.org/TR/ldp/</biblioid>
    </biblioentry>

    <biblioentry xml:id="sparql" xreflabel="[5]">
      <abbrev>5</abbrev>
      <title>SPARQL 1.1 Query Language</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Steve</firstname>
            <surname>Harris</surname>
          </personname>
        </author>
        <author>
          <personname>
            <firstname>Andy</firstname>
            <surname>Seaborne</surname>
          </personname>
        </author>
      </authorgroup>
      <publishername>World Wide Web Consortium (W3C)</publishername>
      <pubdate>21 March 2013</pubdate>
      <biblioid class="uri">https://www.w3.org/TR/sparql11-query/</biblioid>
    </biblioentry>

    <biblioentry xml:id="lda" xreflabel="[6]">
      <abbrev>6</abbrev>
      <title>Linked Data API Specification</title>
      <biblioid class="uri"
        >https://github.com/UKGovLD/linked-data-api/blob/wiki/Specification.md</biblioid>
    </biblioentry>

    <biblioentry xml:id="hydra" xreflabel="[7]">
      <abbrev>7</abbrev>
      <title>Hydra Core Vocabulary</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Markus</firstname>
            <surname>Lanthaler</surname>
          </personname>
        </author>
      </authorgroup>
      <pubdate>20 March 2016</pubdate>
      <biblioid class="uri">http://www.hydra-cg.com/spec/latest/core/</biblioid>
    </biblioentry>

    <biblioentry xml:id="agent-web" xreflabel="[8]">
      <abbrev>8</abbrev>
      <title>Agents and the Semantic Web</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>James</firstname>
            <surname>Hendler</surname>
          </personname>
        </author>
      </authorgroup>
      <pubdate>2001</pubdate>
      <biblioid class="uri">http://www.cs.rpi.edu/~hendler/AgentWeb.html</biblioid>
    </biblioentry>

    <biblioentry xml:id="ontology-driven" xreflabel="[9]">
      <abbrev>9</abbrev>
      <title>Ontology-Driven Apps Using Generic Applications</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Michael</firstname>
            <othername>K.</othername>
            <surname>Bergman</surname>
          </personname>
        </author>
      </authorgroup>
      <pubdate>7 March 2011</pubdate>
      <biblioid class="uri"
        >http://www.mkbergman.com/948/ontology-driven-apps-using-generic-applications/</biblioid>
    </biblioentry>

    <biblioentry xml:id="xslt" xreflabel="[10]">
      <abbrev>10</abbrev>
      <title>XSL Transformations (XSLT) Version 2.0</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Michael</firstname>
            <surname>Kay</surname>
          </personname>
        </author>
      </authorgroup>
      <publishername>World Wide Web Consortium (W3C)</publishername>
      <pubdate>23 January 2007</pubdate>
      <biblioid class="uri">https://www.w3.org/TR/xslt20/</biblioid>
    </biblioentry>

    <biblioentry xml:id="sioc" xreflabel="[11]">
      <abbrev>11</abbrev>
      <title>SIOC Core Ontology Specification</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Uldis</firstname>
            <surname>Bojārs</surname>
          </personname>
        </author>
        <author>
          <personname>
            <firstname>John</firstname>
            <othername>G.</othername>
            <surname>Breslin</surname>
          </personname>
        </author>
      </authorgroup>
      <publishername>DERI, NUI Galway</publishername>
      <pubdate>25 March 2010</pubdate>
      <biblioid class="uri">http://rdfs.org/sioc/spec/</biblioid>
    </biblioentry>

    <biblioentry xml:id="jax-rs" xreflabel="[12]">
      <abbrev>12</abbrev>
      <title>JAX-RS: Java™ API for RESTful Web Services</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Marc</firstname>
            <surname>Hadley</surname>
          </personname>
        </author>
        <author>
          <personname>
            <firstname>Paul</firstname>
            <surname>Sandoz</surname>
          </personname>
        </author>
      </authorgroup>
      <publishername>Sun Microsystems, Inc.</publishername>
      <pubdate>17 September 2009</pubdate>
      <biblioid class="uri"
        >https://jsr311.java.net/nonav/releases/1.1/spec/spec3.html#x3-300003.4</biblioid>
    </biblioentry>

    <biblioentry xml:id="spin" xreflabel="[13]">
      <abbrev>13</abbrev>
      <title>SPIN - Modeling Vocabulary</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Holger</firstname>
            <surname>Knublauch</surname>
          </personname>
        </author>
      </authorgroup>
      <pubdate>7 November 2014</pubdate>
      <biblioid class="uri">http://spinrdf.org/spin.html</biblioid>
    </biblioentry>

    <biblioentry xml:id="awww" xreflabel="[14]">
      <abbrev>14</abbrev>
      <title>Architecture of the World Wide Web, Volume One</title>
      <authorgroup>
        <author>
          <personname>
            <firstname>Ian</firstname>
            <surname>Jacobs</surname>
          </personname>
        </author>
        <author>
          <personname>
            <firstname>Norman</firstname>
            <surname>Walsh</surname>
          </personname>
        </author>
      </authorgroup>
      <publishername>World Wide Web Consortium (W3C)</publishername>
      <pubdate>15 December 2004</pubdate>
      <biblioid class="uri">https://www.w3.org/TR/webarch/#interaction</biblioid>
    </biblioentry>

    <biblioentry>
      <title>Icons used in the diagram made by <link xl:href="http://www.freepik.com/"
          >Freepik</link></title>
      <biblioid class="uri">www.flaticon.com</biblioid>
    </biblioentry>

  </bibliography>

</article>
